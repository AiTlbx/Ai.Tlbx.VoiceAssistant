@page "/"
@using Ai.Tlbx.VoiceAssistant
@using Ai.Tlbx.VoiceAssistant.Provider.OpenAi
@using Ai.Tlbx.VoiceAssistant.Provider.OpenAi.Models
@using Ai.Tlbx.VoiceAssistant.WebUi.Components
@using Ai.Tlbx.VoiceAssistant.Demo.Web
@using Ai.Tlbx.VoiceAssistant.Models
@using System.Diagnostics

@rendermode InteractiveServer
@inject VoiceAssistant voiceAssistant
@inject IJSRuntime JS
@implements IDisposable

<PageTitle>AI Voice Chat</PageTitle>

<CascadingValue Value="voiceAssistant">
    <CascadingValue Value="sessionSettings">
        <div class="min-h-screen bg-gray-50 p-3">
            <div class="max-w-7xl mx-auto">
                <!-- Page Header -->
                <div class="mb-3">
                    <h1 class="text-xl font-semibold text-gray-900">AI Voice Chat</h1>
                </div>

                <div class="flex flex-col lg:flex-row gap-3">
                    <!-- Controls Panel -->
                    <div class="lg:w-1/3">
                        <div class="bg-white rounded-lg shadow-sm border border-gray-200">
                            <div class="border-b border-gray-200 px-3 py-2">
                                <h3 class="text-sm font-medium text-gray-700">Controls</h3>
                            </div>

                            <div class="p-3 space-y-3">
                                <!-- Talk Button -->
                                <AiTalkControl OnStartTalking="StartSession" OnStopTalking="StopSession" IsTalking="voiceAssistant.IsRecording" Loading="voiceAssistant.IsConnecting || voiceAssistant.IsRecording" />

                                <!-- Voice Selection -->
                                <div>
                                    <label for="voiceSelect" class="block text-xs font-medium text-gray-600 mb-1">Voice</label>
                                    <VoiceSelect SelectedVoice="@currentVoiceString" SelectedVoiceChanged="OnVoiceChanged" Disabled="@(voiceAssistant.IsConnecting || voiceAssistant.IsRecording)" />
                                </div>

                                <!-- Voice Speed -->
                                <VoiceSpeedSlider SelectedSpeed="@currentVoiceSpeed" SelectedSpeedChanged="OnVoiceSpeedChanged" Disabled="@(voiceAssistant.IsConnecting || voiceAssistant.IsRecording)" />

                                <!-- Microphone Selection -->
                                <div>
                                    <label class="block text-xs font-medium text-gray-600 mb-1">Microphone</label>
                                    <MicrophoneSelect AvailableMicrophones="availableMicrophones" 
                                                     @bind-SelectedMicrophoneId="selectedMicrophoneId" 
                                                     MicPermissionGranted="micPermissionGranted" 
                                                     OnRequestPermission="RequestMicrophonePermission" 
                                                     Disabled="@(voiceAssistant.IsConnecting || voiceAssistant.IsRecording)" />
                                </div>

                                <!-- Options -->
                                <div class="flex items-center">
                                    <input type="checkbox" id="timeToolCheck" class="h-3 w-3 text-blue-600 border-gray-300 rounded focus:ring-1 focus:ring-blue-500 mr-2" 
                                    @bind="useTimeTool" 
                                    disabled="@voiceAssistant.IsRecording"> 
                                    <label for="timeToolCheck" class="text-xs text-gray-600 cursor-pointer">Enable time tool</label>
                                </div>

                                <!-- Action Buttons -->
                                <div class="space-y-2">
                                    <button class="w-full py-2 px-3 rounded-md bg-gray-600 text-white text-sm font-medium hover:bg-gray-700 transition-colors flex items-center justify-center"
                                    @onclick="ClearChat"
                                    disabled="@(voiceAssistant.IsConnecting || voiceAssistant.IsRecording)">
                                        <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1.5" viewBox="0 0 20 20" fill="currentColor">
                                            <path fill-rule="evenodd" d="M9 2a1 1 0 00-.894.553L7.382 4H4a1 1 0 000 2v10a2 2 0 002 2h8a2 2 0 002-2V6a1 1 0 100-2h-3.382l-.724-1.447A1 1 0 0011 2H9zM7 8a1 1 0 012 0v6a1 1 0 11-2 0V8zm5-1a1 1 0 00-1 1v6a1 1 0 102 0V8a1 1 0 00-1-1z" clip-rule="evenodd" />
                                        </svg>
                                        Clear Chat
                                    </button>

                                    <MicTestWidget OnStartTest="TestMicrophone" Loading="voiceAssistant.IsMicrophoneTesting || voiceAssistant.IsConnecting || voiceAssistant.IsRecording" />
                                </div>

                                <!-- Status -->
                                <div>
                                    <StatusWidget ConnectionStatus="@voiceAssistant.ConnectionStatus" Error="@voiceAssistant.LastErrorMessage" IsMicrophoneTesting="@voiceAssistant.IsMicrophoneTesting" />
                                </div>

                                <!-- Connection Events -->
                                @if (!string.IsNullOrEmpty(lastConnectionEvent))
                                {
                                    <div class="border-t pt-3">
                                        <label class="block text-xs font-medium text-gray-600 mb-1">Last Event</label>
                                        <div class="text-xs text-gray-700 bg-gray-50 rounded px-2 py-1">
                                            @lastConnectionEvent
                                        </div>
                                    </div>
                                }
                            </div>
                        </div>
                    </div>

                    <!-- Chat Panel -->
                    <div class="lg:w-2/3">
                        <div class="bg-white rounded-lg shadow-sm border border-gray-200 h-[500px] flex flex-col overflow-hidden">
                            <div class="border-b border-gray-200 px-3 py-2">
                                <h3 class="text-sm font-medium text-gray-700">Conversation</h3>
                            </div>

                            <div class="flex-1 p-3 overflow-y-auto bg-gray-50" id="chat-messages" @ref="chatContainer">
                                <ChatWidget />
                            </div>

                            <div class="px-3 py-2 border-t border-gray-200 bg-white">
                                @if (voiceAssistant.IsRecording)
                                {
                                    <div class="flex items-center text-red-600 text-sm">
                                        <div class="relative h-2 w-2 mr-2">
                                            <span class="animate-ping absolute h-2 w-2 rounded-full bg-red-400 opacity-75"></span>
                                            <span class="absolute h-2 w-2 rounded-full bg-red-500"></span>
                                        </div>
                                        <span>Listening...</span>
                                    </div>
                                }
                                else
                                {
                                    <span class="text-gray-500 text-sm">Ready</span>
                                }
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </CascadingValue>
</CascadingValue>

@code 
{
    private ElementReference chatContainer;
    private string currentVoiceString = string.Empty;
    private AssistantVoice currentVoice = AssistantVoice.Alloy;
    private double currentVoiceSpeed = 1.0;
    private bool useTimeTool = true;
    
    // Microphone selection related fields
    private List<MicrophoneSelect.MicrophoneInfo> availableMicrophones = new();
    private string selectedMicrophoneId = string.Empty;
    private bool micPermissionGranted = false;

    private SessionSettingsContext sessionSettings = new();
    private string lastConnectionEvent = string.Empty;

    protected override async Task OnInitializedAsync()
    {
        voiceAssistant.OnConnectionStatusChanged = OnConnectionStatusChanged;
        voiceAssistant.OnMessageAdded = OnMessageAdded;
        voiceAssistant.OnMicrophoneDevicesChanged = OnMicrophoneDevicesChanged;

        // Initialize the string value based on the current enum value
        // Note: CurrentVoice is not exposed by VoiceAssistant
        // currentVoiceString = voiceAssistant.CurrentVoice.ToString().ToLower();

        // Don't check for microphone permission in OnInitializedAsync (during prerender)
        // We'll do that in OnAfterRenderAsync instead
        await Task.CompletedTask;
    }
    
    // Logging method using the centralized logging system
    private void Log(LogLevel level, string message)
    {
        // Direct logging is not exposed in VoiceAssistant
        Debug.WriteLine($"WebDemoLog: [{level}] [Home] {message}");
    }

    private async Task CheckMicrophonePermission()
    {
        try
        {
            // Try to get microphones - this will succeed if permission is already granted
            var mics = await voiceAssistant.GetAvailableMicrophonesAsync();
            
            // Check if we have actual device information - actual device labels mean permission is granted
            bool hasRealDeviceNames = mics.Count > 0 && 
                mics.Any(m => !string.IsNullOrEmpty(m.Name) && !m.Name.StartsWith("Microphone "));
            
            micPermissionGranted = hasRealDeviceNames;
            Log(LogLevel.Info, $"Initial permission check: Permission granted: {micPermissionGranted}, Found {mics.Count} microphones");
            
            if (micPermissionGranted)
            {
                // If we got devices with real names, permission is granted
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                
                // Select default or first microphone
                if (availableMicrophones.Count > 0)
                {
                    var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                    selectedMicrophoneId = defaultMic?.Id ?? availableMicrophones[0].Id;
                    // Note: SetMicrophoneDevice might need to be implemented differently
                    
                    Log(LogLevel.Info, $"Initially selected microphone: {availableMicrophones.FirstOrDefault(m => m.Id == selectedMicrophoneId)?.Name ?? "Unknown"}");
                }
            }
            else if (mics.Count > 0)
            {
                // We have devices but without proper labels - this suggests permission is needed
                // but we still store them for when permission is granted
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                Log(LogLevel.Info, "Microphones found but without proper labels - permission needed");
            }
            else
            {
                Log(LogLevel.Warn, "No microphones found or permission not granted");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error checking microphone permission: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
            micPermissionGranted = false;
        }
        finally
        {
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task CheckMicrophonePermissionState()
    {
        try
        {
            // Just get available microphones - the JS will check permissions without activating
            var mics = await voiceAssistant.GetAvailableMicrophonesAsync();
            
            // Check if we have actual device information - actual device labels mean permission is granted
            bool hasRealDeviceNames = mics.Count > 0 && 
                mics.Any(m => !string.IsNullOrEmpty(m.Name) && !m.Name.StartsWith("Microphone "));
            
            micPermissionGranted = hasRealDeviceNames;
            Log(LogLevel.Info, $"Permission check: Permission granted: {micPermissionGranted}, Found {mics.Count} microphones");
            
            if (mics.Count > 0)
            {
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                
                // Select default or first microphone
                var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                if (defaultMic != null)
                {
                    selectedMicrophoneId = defaultMic.Id;
                    Log(LogLevel.Info, $"Selected default microphone: {defaultMic.Name}");
                }
                else if (availableMicrophones.Count > 0)
                {
                    selectedMicrophoneId = availableMicrophones[0].Id;
                    Log(LogLevel.Info, $"Selected first microphone: {availableMicrophones[0].Name}");
                }
            }
            else
            {
                Log(LogLevel.Info, "No microphones found or permission not granted");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error checking microphone permission state: {ex.Message}");
            micPermissionGranted = false;
        }
        finally
        {
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task RequestMicrophonePermission()
    {
        try
        {
            // Instead of setting isLoadingMicrophones, we'll rely on micPermissionGranted for UI state
            // isLoadingMicrophones = true;
            await InvokeAsync(StateHasChanged);

            Log(LogLevel.Info, "Explicitly requesting microphone permission...");
            
            // Use the new method that explicitly requests permission and gets labeled devices
            // Request permission by getting devices
            var deviceInfos = await voiceAssistant.GetAvailableMicrophonesAsync();
            
            // Convert to MicrophoneInfo objects
            availableMicrophones = deviceInfos.Select(m => new MicrophoneSelect.MicrophoneInfo
            {
                Id = m.Id,
                Name = m.Name,
                IsDefault = m.IsDefault
            }).ToList();
            
            // Check if we now have devices with real names (not placeholders)
            micPermissionGranted = deviceInfos.Count > 0 && 
                deviceInfos.Any(m => !string.IsNullOrEmpty(m.Name) && !m.Name.StartsWith("Microphone "));
            
            Log(LogLevel.Info, $"After permission request: Permission granted: {micPermissionGranted}, Found {deviceInfos.Count} microphones");
            
            // If we have microphones with permission, select one
            if (micPermissionGranted && availableMicrophones.Count > 0)
            {
                // Try to find default microphone
                var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                if (defaultMic != null)
                {
                    selectedMicrophoneId = defaultMic.Id;
                }
                else if (availableMicrophones.Count > 0)
                {
                    // Otherwise use the first microphone
                    selectedMicrophoneId = availableMicrophones[0].Id;
                }

                // Set the selected device
                if (!string.IsNullOrEmpty(selectedMicrophoneId))
                {
                    // Note: SetMicrophoneDevice might need to be implemented differently
                    var selectedMic = availableMicrophones.FirstOrDefault(m => m.Id == selectedMicrophoneId);
                    Log(LogLevel.Info, $"Selected microphone: {selectedMic?.Name ?? "Unknown"}");
                }
            }
            else
            {
                Log(LogLevel.Warn, "Permission not granted or no microphones with labels found");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error requesting microphone permission: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
        finally
        {
            // isLoadingMicrophones = false;
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task OnVoiceChanged(string newVoice)
    {
        currentVoiceString = newVoice;
        // Store voice selection for next start
        currentVoice = Enum.Parse<AssistantVoice>(newVoice, true);
        sessionSettings = sessionSettings with { SelectedVoice = newVoice };
        await Task.CompletedTask;
    }

    private async Task OnVoiceSpeedChanged(double newSpeed)
    {
        currentVoiceSpeed = newSpeed;
        sessionSettings = sessionSettings with { SelectedSpeed = newSpeed };
        await Task.CompletedTask;
    }

    private void OnMicrophoneDevicesChanged(List<AudioDeviceInfo> devices)
    {
        InvokeAsync(async () => 
        {
            availableMicrophones = devices.Select(m => new MicrophoneSelect.MicrophoneInfo
            {
                Id = m.Id,
                Name = m.Name,
                IsDefault = m.IsDefault
            }).ToList();
            await Task.CompletedTask;
            StateHasChanged();
        });
    }

    private void OnConnectionStatusChanged(string status)
    {
        InvokeAsync(() => 
        {
            if (!string.IsNullOrEmpty(status))
            {
                lastConnectionEvent = $"{DateTime.Now:HH:mm:ss} - {status}";
            }
            StateHasChanged();
        });
    }

    private void OnMessageAdded(ChatMessage message)
    {
        InvokeAsync(async () => {
            StateHasChanged();
            await Task.Delay(50); // Give the DOM time to update
            await ScrollToBottom();
        });
    }

    private async Task ScrollToBottom()
    {
        try
        {
            await JS.InvokeVoidAsync("scrollToBottom", chatContainer);
        }
        catch
        {
            // Ignore JS interop errors
        }
    }

    private async Task StartSession()
    {
        try
        {
            // Store the currently selected device before starting the session
            string deviceToUse = selectedMicrophoneId;
            string deviceName = availableMicrophones.FirstOrDefault(m => m.Id == deviceToUse)?.Name ?? "default device";
            
            // Apply the selected microphone if it has a value
            if (!string.IsNullOrEmpty(deviceToUse))
            {
                // Note: SetMicrophoneDevice might need to be implemented differently
                Log(LogLevel.Info, $"Using microphone: {deviceName} for recording session");
            }

            // Get current settings or create new settings
            // TODO: Implement TimeTool with IVoiceTool interface
            //var tools = new List<IVoiceTool>();
            //if (useTimeTool)
            //{
            //    tools.Add(new TimeTool());
            //}

            var settings = new OpenAiVoiceSettings
            {
                Instructions = "You are a helpful AI assistant. Be friendly, conversational, helpful, and engaging.",
                Voice = currentVoice,
                TalkingSpeed = currentVoiceSpeed,
                Model = "gpt-4o-realtime-preview-2025-06-03"
                // Tools = tools
            };
            
            // Start the session with the configured settings
            await voiceAssistant.StartAsync(settings);
            
            // Even if permission state is lost in the process, we still know we have a valid device
            if (!micPermissionGranted && availableMicrophones.Count > 0)
            {
                micPermissionGranted = true;
            }
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error starting session: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }

    private async Task StopSession()
    {
        try
        {
            await voiceAssistant.StopAsync();
            
            // Ensure mic permission state is preserved after stopping
            if (!micPermissionGranted && availableMicrophones.Count > 0)
            {
                micPermissionGranted = true;
            }
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error stopping session: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }    

    private void ClearChat()
    {
        voiceAssistant.ClearChatHistory();
        InvokeAsync(StateHasChanged);
    }

    private async Task TestMicrophone()
    {
        try
        {
            // Store the currently selected device before testing
            string deviceToUse = selectedMicrophoneId;
            string deviceName = availableMicrophones.FirstOrDefault(m => m.Id == deviceToUse)?.Name ?? "default device";
            
            // Apply the selected microphone if it has a value
            if (!string.IsNullOrEmpty(deviceToUse))
            {
                // Note: SetMicrophoneDevice might need to be implemented differently
                Log(LogLevel.Info, $"Testing microphone: {deviceName}");
            }
            
            await voiceAssistant.TestMicrophoneAsync();
            
            // Even if permission state is lost in the process, we still know we have a valid device
            if (!micPermissionGranted && availableMicrophones.Count > 0)
            {
                micPermissionGranted = true;
            }
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error testing microphone: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }

    public void Dispose()
    {
        voiceAssistant.OnConnectionStatusChanged = null;
        voiceAssistant.OnMessageAdded = null;
        voiceAssistant.OnMicrophoneDevicesChanged = null;
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            // Add JS helper function for scrolling
            await JS.InvokeVoidAsync("eval", @"
                window.scrollToBottom = function(element) {
                    if (element) {
                        element.scrollTop = element.scrollHeight;
                    }
                }
            ");

            // Check microphone permission state without activating microphone
            await CheckMicrophonePermissionState();
        }
    }

    // Helper function to format JSON for display
    private string FormatJson(string? jsonString)
    {
        if (string.IsNullOrWhiteSpace(jsonString))
        {    
            return "(empty)";
        }
        try
        {
            using var jsonDoc = System.Text.Json.JsonDocument.Parse(jsonString);
            return System.Text.Json.JsonSerializer.Serialize(jsonDoc, new System.Text.Json.JsonSerializerOptions { WriteIndented = true });
        }
        catch (System.Text.Json.JsonException)
        {
            // If it's not valid JSON, return the original string
            return jsonString;
        }
        catch (Exception ex)
        {
            return $"Error formatting JSON: {ex.Message}";
        }
    }

    // Helper function to truncate text
    private string TruncateText(string text, int maxLength)
    {
        if (string.IsNullOrEmpty(text) || text.Length <= maxLength)
            return text;
            
        return text.Substring(0, maxLength) + "...";
    }
}

